{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter extraction and first round of cleaning\n",
    "This notebook aims to retrieve tweets from the *Twitter API* using `tweepy` library and then make a first round of cleaning them (e.g. *drop duplicates*, *sort it* by date, apply some *regex*) and stored them in a csv.\n",
    "\n",
    "**Working on it...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tweepy\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# My module\n",
    "import my_email\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiding secret API keys in Environment Variables\n",
    "consumer_key = config.CONSUMER_KEY\n",
    "consumer_secret = config.CONSUMER_SECRET\n",
    "\n",
    "access_token = config.ACCESS_TOKEN\n",
    "access_token_secret = config.ACCESS_TOKEN_SECRET\n",
    "\n",
    "bearer_token = config.BEARER_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Bitcoin OR BTC OR #Bitcoin OR #BTC OR $Bitcoin OR $BTC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access granted :)\n"
     ]
    }
   ],
   "source": [
    "# Check access to the API\n",
    "auth = tweepy.AppAuthHandler(consumer_key, consumer_secret)\n",
    "api = tweepy.API(auth)\n",
    "if(api.verify_credentials):\n",
    "    print(\"Access granted :)\")\n",
    "else:\n",
    "    print(\"Access denied :(\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definning some functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def connect_to_twitter_OAuth2(consumer_key=consumer_key, consumer_secret=consumer_secret):\n",
    "    \"\"\"Sets a connection to the twitter API.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    consumer_key : set by default\n",
    "    consumer_secret : set by default\n",
    "    \"\"\"\n",
    "    auth = tweepy.AppAuthHandler(consumer_key, consumer_secret)\n",
    "    api = tweepy.API(auth)\n",
    "    return api\n",
    "\n",
    "\n",
    "def retrieve_tweets(api, since_id=None, max_id=None):\n",
    "    \"\"\"\n",
    "    It returns a twitter object with 100 tweets of a specific api response.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    api : api connection (required)\n",
    "    since_id : if given, it returns tweets with an ID greater than that (newer)\n",
    "    max_id : if given, it returns tweets with an ID less or equal than that (older) (max. 7 days prior)\n",
    "    \"\"\"\n",
    "    return api.search(q=query,\n",
    "                      lang='en',\n",
    "                      result_type='mixed',\n",
    "                      count=100,\n",
    "                      since_id=since_id,\n",
    "                      max_id=max_id,\n",
    "                      tweet_mode='extended')\n",
    "\n",
    "\n",
    "def extract_tweet_atributes(tweet_object):\n",
    "    \"\"\"It returns a Pandas DataFrame with a tweet per row and its attributes per column.\"\"\"\n",
    "    \n",
    "    tweets_list = []\n",
    "    \n",
    "    for tweet in tweet_object:\n",
    "        # Iterates over each tweet and gets its attributes\n",
    "        tweet_id = tweet.id   # Unique tweet identifier\n",
    "        text = tweet.full_text   # Sring, text of the tweet\n",
    "        screen_name = tweet.user.screen_name   # String, username\n",
    "        followers = tweet.user.followers_count   # Number of followers\n",
    "        retweet_count = tweet.retweet_count   # Number of retweets\n",
    "        favorite_count = tweet.favorite_count   # Number of favorites\n",
    "        created_at = tweet.created_at   # UTC time tweet created\n",
    "        source = tweet.source   # Utility used to post the tweet\n",
    "        # Append attributes to list\n",
    "        tweets_list.append({'tweet_id':tweet_id,\n",
    "                            'text':text, \n",
    "                            'screen_name':screen_name,\n",
    "                            'followers':followers,\n",
    "                            'retweet_count':retweet_count, \n",
    "                            'favorite_count':favorite_count, \n",
    "                            'created_at':created_at, \n",
    "                            'source':source})\n",
    "    # Creates a DataFrame\n",
    "    df = pd.DataFrame(tweets_list, columns=['tweet_id',\n",
    "                                            'text',\n",
    "                                            'screen_name',\n",
    "                                            'followers',\n",
    "                                            'retweet_count',\n",
    "                                            'favorite_count', \n",
    "                                            'created_at',\n",
    "                                            'source'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def first_cleaning(df):\n",
    "    \"\"\"It returns a DataFrame after dropping duplicates (subset=['tweet_id']) and sorting it (by='tweet_id')\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : Pandas DataFrame to clean.\n",
    "    \"\"\"\n",
    "    df_no_dup = df.drop_duplicates(subset=['tweet_id'], ignore_index=True)\n",
    "    cleaned_df = df_no_dup.sort_values(by='tweet_id', ignore_index=True)\n",
    "    return cleaned_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**API rate limits:** Maximum of 450 requests per 15 minutes. Endpoint: Recent Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main functions\n",
    "\n",
    "def main_retrieval(file_path, last_id=None):\n",
    "    \"\"\"\n",
    "    Main retrieval function.\n",
    "    It makes 450 requests.\n",
    "    It saves a DataFrame to a csv in a given path.\n",
    "    \n",
    "    Returns \n",
    "    -------\n",
    "    + Last tweet id.\n",
    "    + DataFrame length\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : file where the DataFrame will be stored (append mode)\n",
    "    last_id : if given, it retrieves tweets only with a greter ID (older)\n",
    "    \"\"\"\n",
    "    # Set a connection to the api\n",
    "    api = connect_to_twitter_OAuth2()\n",
    "    # Set some required variables\n",
    "    number_of_requests = 450\n",
    "    dfs = []\n",
    "    # Main loop\n",
    "    for i in tqdm(range(number_of_requests)):\n",
    "        \n",
    "        crypto_tweets = retrieve_tweets(api, since_id=last_id)\n",
    "        df = extract_tweet_atributes(crypto_tweets)\n",
    "        # Set a new last_id. Next iteration starts taking tweets from it on\n",
    "        last_id = df['tweet_id'].max()\n",
    "        dfs.append(df)\n",
    "\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    df = first_cleaning(df)\n",
    "    last_id = df['tweet_id'].max()\n",
    "    # Saves df to a csv in the file_path, ignoring index, appending it, and not writting column names each time\n",
    "    df.to_csv(file_path, sep=',', index=False, mode='a', header=False)\n",
    "\n",
    "    return last_id, len(df)\n",
    "\n",
    "\n",
    "\n",
    "def long_term_retrieval(file_path, iterations=25, last_id=None):\n",
    "    \"\"\"\n",
    "    It aims to be retrieving tweets for a long period, 10 hours.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : file where the DataFrame will be stored (append mode).\n",
    "    iterations : number of main_retrieval function calls. 15 iterations -> 11 hours period.\n",
    "    last_id : if given, it retrieves tweets only with a greter ID (older).\n",
    "    \"\"\"\n",
    "    lap = 0\n",
    "    while lap <= iterations:\n",
    "        # Try to retrieve tweets or sends an email if it cannot. It does not break the loop\n",
    "        try:\n",
    "            # Set the next last_id and the length of the DataFrame that just added to the csv\n",
    "            last_id, length = main_retrieval(file_path=file_path, last_id=last_id)\n",
    "            print(f'{length} new rows added to the csv.')\n",
    "        except:\n",
    "            print('Error!')\n",
    "            my_email.error_email()\n",
    "        # Release the counter and break the loop if necessary\n",
    "        lap += 1\n",
    "        if lap > iterations:\n",
    "            break\n",
    "        print(f'{(iterations + 1) - lap} laps to go.')\n",
    "        # Check if it's the last lap\n",
    "        if lap == iterations:\n",
    "            my_email.last_lap_reminder()\n",
    "        # Checks the battery and sends an email if its low\n",
    "        if my_email.check_battery() < 20:\n",
    "            my_email.warning()            \n",
    "        # Time info\n",
    "        now = datetime.now()\n",
    "        current_time = now.strftime(\"%H:%M:%S\")\n",
    "        print(f'Getting some sleep @ {current_time}...')\n",
    "        # Getting some sleep til next main retrieval\n",
    "        time.sleep(20 * 60)\n",
    "        print('*' * 50)\n",
    "    print('Done :D\\nEnjoy it!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path where the set of tweets will be stored to play with them\n",
    "file_path = 'C:/Users/Javi/Desktop/cryptocurrency_predictor/data/twitter/raw_tweets.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 450/450 [05:13<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "872 new rows added to the csv.\n",
      "45 laps to go.\n",
      "Getting some sleep @ 10:33:01...\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 450/450 [06:10<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "944 new rows added to the csv.\n",
      "44 laps to go.\n",
      "Getting some sleep @ 10:59:12...\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 450/450 [05:08<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "730 new rows added to the csv.\n",
      "43 laps to go.\n",
      "Getting some sleep @ 11:24:21...\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 450/450 [04:57<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715 new rows added to the csv.\n",
      "42 laps to go.\n",
      "Getting some sleep @ 11:49:19...\n"
     ]
    }
   ],
   "source": [
    "long_term_retrieval(file_path, iterations=45, last_id=1367401531377676288)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weaknesses: \n",
    "# 1. It gave an error: number of requests exceded :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm afraid the method `since_id` from `api.search()` function doesn't work quite as expected :(. It seems that it's able to retrieve tweets just **one hour old**.\n",
    "\n",
    "Therefore, there's gonna always be a period of time where data is missing (between each time I run the *main* cell) unless the script is continuously running (for 10/14 days or so) :(((."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Truncated tweets\n",
    "Texts over 140 characters are truncated. There could be a solution, adding `tweet_mode='extended'` parameter when calling my \"retrive_tweets\" function. <br>\n",
    "Let's see it in action!\n",
    "\n",
    "AND IT WORKS!!! We got the full text of the tweet! Take that Twitter!\n",
    "It doesn't work for retweets though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First look at the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'C:/Users/Javi/Desktop/cryptocurrency_predictor/data/twitter/raw_tweets.csv'\n",
    "columns = ['tweet_id',\n",
    "           'text',\n",
    "           'screen_name',\n",
    "           'followers',\n",
    "           'retweet_count',\n",
    "           'favorite_count', \n",
    "           'created_at',\n",
    "           'source']\n",
    "\n",
    "data = pd.read_csv(file_path, names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 678569 entries, 0 to 678568\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   tweet_id        678569 non-null  int64 \n",
      " 1   text            678569 non-null  object\n",
      " 2   screen_name     678569 non-null  object\n",
      " 3   followers       678569 non-null  int64 \n",
      " 4   retweet_count   678569 non-null  int64 \n",
      " 5   favorite_count  678569 non-null  int64 \n",
      " 6   created_at      678569 non-null  object\n",
      " 7   source          670435 non-null  object\n",
      "dtypes: int64(4), object(4)\n",
      "memory usage: 41.4+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>followers</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>created_at</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>678564</th>\n",
       "      <td>1367401527787327491</td>\n",
       "      <td>RT @BTC_Archive: Amazon will probably start ac...</td>\n",
       "      <td>Bakizbe59152255</td>\n",
       "      <td>12</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-04 09:08:23</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678565</th>\n",
       "      <td>1367401528156327939</td>\n",
       "      <td>$STBU #Stobox #STBU #StoboxExchange #cryptocur...</td>\n",
       "      <td>Eliano63659529</td>\n",
       "      <td>1185</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-04 09:08:24</td>\n",
       "      <td>Twitter Web App</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678566</th>\n",
       "      <td>1367401528340795392</td>\n",
       "      <td>@camiloaparedes would it be better for $nano i...</td>\n",
       "      <td>alexjohnward</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-04 09:08:24</td>\n",
       "      <td>Twitter Web App</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678567</th>\n",
       "      <td>1367401531281182720</td>\n",
       "      <td>@bitsee2 @princey1976 @TheRock @acorns I love ...</td>\n",
       "      <td>BitNoi</td>\n",
       "      <td>2120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-04 09:08:24</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678568</th>\n",
       "      <td>1367401531377676288</td>\n",
       "      <td>RT @__Bullish__: ðŸ’» The $MASQ #Giveaway | Rules...</td>\n",
       "      <td>DIKINGVFX</td>\n",
       "      <td>46</td>\n",
       "      <td>2585</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-04 09:08:24</td>\n",
       "      <td>Twitter Web App</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   tweet_id  \\\n",
       "678564  1367401527787327491   \n",
       "678565  1367401528156327939   \n",
       "678566  1367401528340795392   \n",
       "678567  1367401531281182720   \n",
       "678568  1367401531377676288   \n",
       "\n",
       "                                                     text      screen_name  \\\n",
       "678564  RT @BTC_Archive: Amazon will probably start ac...  Bakizbe59152255   \n",
       "678565  $STBU #Stobox #STBU #StoboxExchange #cryptocur...   Eliano63659529   \n",
       "678566  @camiloaparedes would it be better for $nano i...     alexjohnward   \n",
       "678567  @bitsee2 @princey1976 @TheRock @acorns I love ...           BitNoi   \n",
       "678568  RT @__Bullish__: ðŸ’» The $MASQ #Giveaway | Rules...        DIKINGVFX   \n",
       "\n",
       "        followers  retweet_count  favorite_count           created_at  \\\n",
       "678564         12            146               0  2021-03-04 09:08:23   \n",
       "678565       1185              0               0  2021-03-04 09:08:24   \n",
       "678566        260              0               0  2021-03-04 09:08:24   \n",
       "678567       2120              0               0  2021-03-04 09:08:24   \n",
       "678568         46           2585               0  2021-03-04 09:08:24   \n",
       "\n",
       "                    source  \n",
       "678564  Twitter for iPhone  \n",
       "678565     Twitter Web App  \n",
       "678566     Twitter Web App  \n",
       "678567  Twitter for iPhone  \n",
       "678568     Twitter Web App  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.info())\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1367401531377676288"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tweet_id'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
