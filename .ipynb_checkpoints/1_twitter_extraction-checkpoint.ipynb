{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter extraction and first round of cleaning\n",
    "This notebook aims to retrieve tweets from the *Twitter API* using `tweepy` library and then make a first round of cleaning them (e.g. *drop duplicates*, *sort it* by date, apply some *regex*) and stored them in a csv.\n",
    "\n",
    "**Working on it...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tweepy\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# My module\n",
    "import my_email\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiding secret API keys in Environment Variables\n",
    "consumer_key = config.CONSUMER_KEY\n",
    "consumer_secret = config.CONSUMER_SECRET\n",
    "\n",
    "access_token = config.ACCESS_TOKEN\n",
    "access_token_secret = config.ACCESS_TOKEN_SECRET\n",
    "\n",
    "bearer_token = config.BEARER_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Bitcoin OR BTC OR #Bitcoin OR #BTC OR $Bitcoin OR $BTC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access granted :)\n"
     ]
    }
   ],
   "source": [
    "# Check access to the API\n",
    "auth = tweepy.AppAuthHandler(consumer_key, consumer_secret)\n",
    "api = tweepy.API(auth)\n",
    "if(api.verify_credentials):\n",
    "    print(\"Access granted :)\")\n",
    "else:\n",
    "    print(\"Access denied :(\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definning some functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def connect_to_twitter_OAuth2(consumer_key=consumer_key, consumer_secret=consumer_secret):\n",
    "    \"\"\"Sets a connection to the twitter API.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    consumer_key : set by default\n",
    "    consumer_secret : set by default\n",
    "    \"\"\"\n",
    "    auth = tweepy.AppAuthHandler(consumer_key, consumer_secret)\n",
    "    api = tweepy.API(auth)\n",
    "    return api\n",
    "\n",
    "\n",
    "def retrieve_tweets(api, since_id=None, max_id=None):\n",
    "    \"\"\"\n",
    "    It returns a twitter object with 100 tweets of a specific api response.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    api : api connection (required)\n",
    "    since_id : if given, it returns tweets with an ID greater than that (newer)\n",
    "    max_id : if given, it returns tweets with an ID less or equal than that (older) (max. 7 days prior)\n",
    "    \"\"\"\n",
    "    return api.search(q=query,\n",
    "                      lang='en',\n",
    "                      result_type='mixed',\n",
    "                      count=100,\n",
    "                      since_id=since_id,\n",
    "                      max_id=max_id,\n",
    "                      tweet_mode='extended')\n",
    "\n",
    "\n",
    "def extract_tweet_atributes(tweet_object):\n",
    "    \"\"\"It returns a Pandas DataFrame with a tweet per row and its attributes per column.\"\"\"\n",
    "    \n",
    "    tweets_list = []\n",
    "    \n",
    "    for tweet in tweet_object:\n",
    "        # Iterates over each tweet and gets its attributes\n",
    "        tweet_id = tweet.id   # Unique tweet identifier\n",
    "        text = tweet.full_text   # Sring, text of the tweet\n",
    "        screen_name = tweet.user.screen_name   # String, username\n",
    "        followers = tweet.user.followers_count   # Number of followers\n",
    "        retweet_count = tweet.retweet_count   # Number of retweets\n",
    "        favorite_count = tweet.favorite_count   # Number of favorites\n",
    "        created_at = tweet.created_at   # UTC time tweet created\n",
    "        source = tweet.source   # Utility used to post the tweet\n",
    "        # Append attributes to list\n",
    "        tweets_list.append({'tweet_id':tweet_id,\n",
    "                            'text':text, \n",
    "                            'screen_name':screen_name,\n",
    "                            'followers':followers,\n",
    "                            'retweet_count':retweet_count, \n",
    "                            'favorite_count':favorite_count, \n",
    "                            'created_at':created_at, \n",
    "                            'source':source})\n",
    "    # Creates a DataFrame\n",
    "    df = pd.DataFrame(tweets_list, columns=['tweet_id',\n",
    "                                            'text',\n",
    "                                            'screen_name',\n",
    "                                            'followers',\n",
    "                                            'retweet_count',\n",
    "                                            'favorite_count', \n",
    "                                            'created_at',\n",
    "                                            'source'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def first_cleaning(df):\n",
    "    \"\"\"It returns a DataFrame after dropping duplicates (subset=['tweet_id']) and sorting it (by='tweet_id')\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : Pandas DataFrame to clean.\n",
    "    \"\"\"\n",
    "    df_no_dup = df.drop_duplicates(subset=['tweet_id'], ignore_index=True)\n",
    "    cleaned_df = df_no_dup.sort_values(by='tweet_id', ignore_index=True)\n",
    "    return cleaned_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**API rate limits:** Maximum of 450 requests per 15 minutes. Endpoint: Recent Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main functions\n",
    "\n",
    "def main_retrieval(file_path, last_id=None):\n",
    "    \"\"\"\n",
    "    Main retrieval function.\n",
    "    It makes 450 requests.\n",
    "    It saves a DataFrame to a csv in a given path.\n",
    "    \n",
    "    Returns \n",
    "    -------\n",
    "    + Last tweet id.\n",
    "    + DataFrame length\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : file where the DataFrame will be stored (append mode)\n",
    "    last_id : if given, it retrieves tweets only with a greter ID (older)\n",
    "    \"\"\"\n",
    "    # Set a connection to the api\n",
    "    api = connect_to_twitter_OAuth2()\n",
    "    # Set some required variables\n",
    "    number_of_requests = 450\n",
    "    dfs = []\n",
    "    # Main loop\n",
    "    for i in tqdm(range(number_of_requests)):\n",
    "        \n",
    "        crypto_tweets = retrieve_tweets(api, since_id=last_id)\n",
    "        df = extract_tweet_atributes(crypto_tweets)\n",
    "        # Set a new last_id. Next iteration starts taking tweets from it on\n",
    "        last_id = df['tweet_id'].max()\n",
    "        dfs.append(df)\n",
    "\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    df = first_cleaning(df)\n",
    "    last_id = df['tweet_id'].max()\n",
    "    # Saves df to a csv in the file_path, ignoring index, appending it, and not writting column names each time\n",
    "    df.to_csv(file_path, sep=',', index=False, mode='a', header=False)\n",
    "\n",
    "    return last_id, len(df)\n",
    "\n",
    "\n",
    "\n",
    "def long_term_retrieval(file_path, iterations=25, last_id=None):\n",
    "    \"\"\"\n",
    "    It aims to be retrieving tweets for a long period, 10 hours.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : file where the DataFrame will be stored (append mode).\n",
    "    iterations : number of main_retrieval function calls. 15 iterations -> 11 hours period.\n",
    "    last_id : if given, it retrieves tweets only with a greter ID (older).\n",
    "    \"\"\"\n",
    "    lap = 0\n",
    "    while lap <= iterations:\n",
    "        # Try to retrieve tweets or sends an email if it cannot. It does not break the loop\n",
    "        try:\n",
    "            # Set the next last_id and the length of the DataFrame that just added to the csv\n",
    "            last_id, length = main_retrieval(file_path=file_path, last_id=last_id)\n",
    "            print(f'{length} new rows added to the csv.')\n",
    "        except:\n",
    "            print('Error!')\n",
    "            my_email.error_email()\n",
    "        # Release the counter and break the loop if necessary\n",
    "        lap += 1\n",
    "        if lap > iterations:\n",
    "            break\n",
    "        print(f'{(iterations + 1) - lap} laps to go.')\n",
    "        # Check if it's the last lap\n",
    "        if lap == iterations:\n",
    "            my_email.last_lap_reminder()\n",
    "        # Checks the battery and sends an email if its low\n",
    "        if my_email.check_battery() < 20:\n",
    "            my_email.warning()            \n",
    "        # Time info\n",
    "        now = datetime.now()\n",
    "        current_time = now.strftime(\"%H:%M:%S\")\n",
    "        print(f'Getting some sleep @ {current_time}...')\n",
    "        # Getting some sleep til next main retrieval\n",
    "        time.sleep(20 * 60)\n",
    "        print('*' * 50)\n",
    "    print('Done :D\\nEnjoy it!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path where the set of tweets will be stored to play with them\n",
    "file_path = 'C:/Users/Javi/Desktop/cryptocurrency_predictor/data/twitter/raw_tweets.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(12 * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 450/450 [04:49<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "991 new rows added to the csv.\n",
      "50 laps to go.\n",
      "Getting some sleep @ 18:35:58...\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 450/450 [04:43<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1108 new rows added to the csv.\n",
      "49 laps to go.\n",
      "Getting some sleep @ 19:00:43...\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 450/450 [04:42<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1068 new rows added to the csv.\n",
      "48 laps to go.\n",
      "Getting some sleep @ 19:25:26...\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 450/450 [05:19<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1253 new rows added to the csv.\n",
      "47 laps to go.\n",
      "Getting some sleep @ 19:50:47...\n"
     ]
    }
   ],
   "source": [
    "long_term_retrieval(file_path, iterations=50, last_id=1368248674711576580)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weaknesses: \n",
    "# 1. It gave an error: number of requests exceded :("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm afraid the method `since_id` from `api.search()` function doesn't work quite as expected :(. It seems that it's able to retrieve tweets just **one hour old**.\n",
    "\n",
    "Therefore, there's gonna always be a period of time where data is missing (between each time I run the *main* cell) unless the script is continuously running (for 10/14 days or so) :(((."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Truncated tweets\n",
    "Texts over 140 characters are truncated. There could be a solution, adding `tweet_mode='extended'` parameter when calling my \"retrive_tweets\" function. <br>\n",
    "Let's see it in action!\n",
    "\n",
    "AND IT WORKS!!! We got the full text of the tweet! Take that Twitter!\n",
    "It doesn't work for retweets though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First look at the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'C:/Users/Javi/Desktop/cryptocurrency_predictor/data/twitter/raw_tweets.csv'\n",
    "columns = ['tweet_id',\n",
    "           'text',\n",
    "           'screen_name',\n",
    "           'followers',\n",
    "           'retweet_count',\n",
    "           'favorite_count', \n",
    "           'created_at',\n",
    "           'source']\n",
    "\n",
    "data = pd.read_csv(file_path, names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 798963 entries, 0 to 798962\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count   Dtype \n",
      "---  ------          --------------   ----- \n",
      " 0   tweet_id        798963 non-null  int64 \n",
      " 1   text            798963 non-null  object\n",
      " 2   screen_name     798963 non-null  object\n",
      " 3   followers       798963 non-null  int64 \n",
      " 4   retweet_count   798963 non-null  int64 \n",
      " 5   favorite_count  798963 non-null  int64 \n",
      " 6   created_at      798963 non-null  object\n",
      " 7   source          788591 non-null  object\n",
      "dtypes: int64(4), object(4)\n",
      "memory usage: 48.8+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>followers</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>created_at</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>798958</th>\n",
       "      <td>1368248669804269568</td>\n",
       "      <td>RT @iamZatoshi: 🔥🐉 BITCOIN SV GIVEAWAY 🐉🔥 \\n\\n...</td>\n",
       "      <td>AirdropHunter86</td>\n",
       "      <td>122</td>\n",
       "      <td>3432</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-06 17:14:38</td>\n",
       "      <td>Twitter for Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798959</th>\n",
       "      <td>1368248672295731200</td>\n",
       "      <td>RT @VentureCoinist: Bitcoin pumping because......</td>\n",
       "      <td>CryptoEuclid_</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-06 17:14:38</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798960</th>\n",
       "      <td>1368248672467570689</td>\n",
       "      <td>RT @NitroExOfficial: Our first event is #Airdr...</td>\n",
       "      <td>Siddhes26270348</td>\n",
       "      <td>31</td>\n",
       "      <td>12444</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-06 17:14:39</td>\n",
       "      <td>Twitter for Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798961</th>\n",
       "      <td>1368248673365192707</td>\n",
       "      <td>@ThuanCapital millionaires they don't care abo...</td>\n",
       "      <td>akevinhao</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-06 17:14:39</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798962</th>\n",
       "      <td>1368248674711576580</td>\n",
       "      <td>\"Supporting NitroEx Exchange for my own future...</td>\n",
       "      <td>Ayush81223104</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-06 17:14:39</td>\n",
       "      <td>Twitter Web App</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   tweet_id  \\\n",
       "798958  1368248669804269568   \n",
       "798959  1368248672295731200   \n",
       "798960  1368248672467570689   \n",
       "798961  1368248673365192707   \n",
       "798962  1368248674711576580   \n",
       "\n",
       "                                                     text      screen_name  \\\n",
       "798958  RT @iamZatoshi: 🔥🐉 BITCOIN SV GIVEAWAY 🐉🔥 \\n\\n...  AirdropHunter86   \n",
       "798959  RT @VentureCoinist: Bitcoin pumping because......    CryptoEuclid_   \n",
       "798960  RT @NitroExOfficial: Our first event is #Airdr...  Siddhes26270348   \n",
       "798961  @ThuanCapital millionaires they don't care abo...        akevinhao   \n",
       "798962  \"Supporting NitroEx Exchange for my own future...    Ayush81223104   \n",
       "\n",
       "        followers  retweet_count  favorite_count           created_at  \\\n",
       "798958        122           3432               0  2021-03-06 17:14:38   \n",
       "798959          1             38               0  2021-03-06 17:14:38   \n",
       "798960         31          12444               0  2021-03-06 17:14:39   \n",
       "798961          7              0               0  2021-03-06 17:14:39   \n",
       "798962         29              0               0  2021-03-06 17:14:39   \n",
       "\n",
       "                     source  \n",
       "798958  Twitter for Android  \n",
       "798959   Twitter for iPhone  \n",
       "798960  Twitter for Android  \n",
       "798961   Twitter for iPhone  \n",
       "798962      Twitter Web App  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.info())\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1368248674711576580"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tweet_id'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
