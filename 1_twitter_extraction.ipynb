{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter extraction and first round of cleaning\n",
    "This notebook aims to retrieve tweets from the *Twitter API* using `tweepy` library and then make a first round of cleaning them (e.g. *drop duplicates*, *sort it* by date, apply some *regex*) and stored them in a csv.\n",
    "\n",
    "**Working on it...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tweepy\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# My module\n",
    "import my_email\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiding secret API keys in Environment Variables\n",
    "consumer_key = config.CONSUMER_KEY\n",
    "consumer_secret = config.CONSUMER_SECRET\n",
    "\n",
    "access_token = config.ACCESS_TOKEN\n",
    "access_token_secret = config.ACCESS_TOKEN_SECRET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Bitcoin OR BTC OR #Bitcoin OR #BTC OR $Bitcoin OR $BTC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access granted :)\n"
     ]
    }
   ],
   "source": [
    "# Check access to the API\n",
    "auth = tweepy.AppAuthHandler(consumer_key, consumer_secret)\n",
    "api = tweepy.API(auth)\n",
    "if(api.verify_credentials):\n",
    "    print(\"Access granted :)\")\n",
    "else:\n",
    "    print(\"Access denied :(\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definning some functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def connect_to_twitter_OAuth2(consumer_key=consumer_key, consumer_secret=consumer_secret):\n",
    "    \"\"\"Sets a connection to the twitter API.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    consumer_key : set by default\n",
    "    consumer_secret : set by default\n",
    "    \"\"\"\n",
    "    auth = tweepy.AppAuthHandler(consumer_key, consumer_secret)\n",
    "    api = tweepy.API(auth)\n",
    "    return api\n",
    "\n",
    "\n",
    "def retrieve_tweets(api, since_id=None, max_id=None):\n",
    "    \"\"\"\n",
    "    It returns a twitter object with 100 tweets of a specific api response.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    api : api connection (required)\n",
    "    since_id : if given, it returns tweets with an ID greater than that (newer)\n",
    "    max_id : if given, it returns tweets with an ID less or equal than that (older) (max. 7 days prior)\n",
    "    \"\"\"\n",
    "    return api.search(q=query,\n",
    "                      \n",
    "                      lang='en',\n",
    "                      result_type='mixed',\n",
    "                      count=100,\n",
    "                      since_id=since_id,\n",
    "                      max_id=max_id,\n",
    "                      tweet_mode='extended')\n",
    "\n",
    "\n",
    "def extract_tweet_atributes(tweet_object):\n",
    "    \"\"\"It returns a Pandas DataFrame with a tweet per row and its attributes per column.\"\"\"\n",
    "    \n",
    "    tweets_list = []\n",
    "    \n",
    "    for tweet in tweet_object:\n",
    "        # Iterates over each tweet and gets its attributes\n",
    "        tweet_id = tweet.id   # Unique tweet identifier\n",
    "        text = tweet.full_text   # Sring, text of the tweet\n",
    "        screen_name = tweet.user.screen_name   # String, username\n",
    "        followers = tweet.user.followers_count   # Number of followers\n",
    "        retweet_count = tweet.retweet_count   # Number of retweets\n",
    "        favorite_count = tweet.favorite_count   # Number of favorites\n",
    "        created_at = tweet.created_at   # UTC time tweet created\n",
    "        source = tweet.source   # Utility used to post the tweet\n",
    "        # Append attributes to list\n",
    "        tweets_list.append({'tweet_id':tweet_id,\n",
    "                            'text':text, \n",
    "                            'screen_name':screen_name,\n",
    "                            'followers':followers,\n",
    "                            'retweet_count':retweet_count, \n",
    "                            'favorite_count':favorite_count, \n",
    "                            'created_at':created_at, \n",
    "                            'source':source})\n",
    "    # Creates a DataFrame\n",
    "    df = pd.DataFrame(tweets_list, columns=['tweet_id',\n",
    "                                            'text',\n",
    "                                            'screen_name',\n",
    "                                            'followers',\n",
    "                                            'retweet_count',\n",
    "                                            'favorite_count', \n",
    "                                            'created_at',\n",
    "                                            'source'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def first_cleaning(df):\n",
    "    \"\"\"It returns a DataFrame after dropping duplicates (subset=['tweet_id']) and sorting it (by='tweet_id')\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : Pandas DataFrame to clean.\n",
    "    \"\"\"\n",
    "    df_no_dup = df.drop_duplicates(subset=['tweet_id'], ignore_index=True)\n",
    "    cleaned_df = df_no_dup.sort_values(by='tweet_id', ignore_index=True)\n",
    "    return cleaned_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**API rate limits:** Maximum of 450 requests per 15 minutes. Endpoint: Recent Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main functions\n",
    "\n",
    "def main_retrieval(file_path, last_id=None):\n",
    "    \"\"\"\n",
    "    Main retrieval function.\n",
    "    It makes 450 requests.\n",
    "    It saves a DataFrame to a csv in a given path.\n",
    "    \n",
    "    Returns \n",
    "    -------\n",
    "    + Last tweet id.\n",
    "    + DataFrame length\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : file where the DataFrame will be stored (append mode)\n",
    "    last_id : if given, it retrieves tweets only with a greter ID (older)\n",
    "    \"\"\"\n",
    "    # Set a connection to the api\n",
    "    api = connect_to_twitter_OAuth2()\n",
    "    # Set some required variables\n",
    "    number_of_requests = 450\n",
    "    dfs = []\n",
    "    # Main loop\n",
    "    for i in tqdm(range(number_of_requests)):\n",
    "        \n",
    "        crypto_tweets = retrieve_tweets(api, since_id=last_id)\n",
    "        df = extract_tweet_atributes(crypto_tweets)\n",
    "        # Set a new last_id. Next iteration starts taking tweets from it on\n",
    "        last_id = df['tweet_id'].max()\n",
    "        dfs.append(df)\n",
    "\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    df = first_cleaning(df)\n",
    "    last_id = df['tweet_id'].max()\n",
    "    # Saves df to a csv in the file_path, ignoring index, appending it, and not writting column names each time\n",
    "    df.to_csv(file_path, sep=',', index=False, mode='a', header=False)\n",
    "\n",
    "    return last_id, len(df)\n",
    "\n",
    "\n",
    "\n",
    "def long_term_retrieval(file_path, iterations=25, last_id=None):\n",
    "    \"\"\"\n",
    "    It aims to be retrieving tweets for a long period, 10 hours.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : file where the DataFrame will be stored (append mode).\n",
    "    iterations : number of main_retrieval function calls. 15 iterations -> 11 hours period.\n",
    "    last_id : if given, it retrieves tweets only with a greter ID (older).\n",
    "    \"\"\"\n",
    "    lap = 0\n",
    "    while lap <= iterations:\n",
    "        # Try to retrieve tweets or sends an email if it cannot. It does not break the loop\n",
    "        try:\n",
    "            # Set the next last_id and the length of the DataFrame that just added to the csv\n",
    "            last_id, length = main_retrieval(file_path=file_path, last_id=last_id)\n",
    "            print(f'{length} new rows added to the csv.')\n",
    "        except:\n",
    "            print('Error!')\n",
    "            my_email.error_email()\n",
    "        # Release the counter and break the loop if necessary\n",
    "        lap += 1\n",
    "        if lap > iterations:\n",
    "            break\n",
    "        print(f'{(iterations + 1) - lap} laps to go.')\n",
    "        # Check if it's the last lap\n",
    "        if lap == iterations:\n",
    "            my_email.last_lap_reminder()\n",
    "        # Checks the battery and sends an email if its low\n",
    "        if my_email.check_battery() < 20:\n",
    "            my_email.warning()            \n",
    "        # Time info\n",
    "        now = datetime.now()\n",
    "        current_time = now.strftime(\"%H:%M:%S\")\n",
    "        print(f'Getting some sleep @ {current_time}...')\n",
    "        # Getting some sleep til next main retrieval\n",
    "        time.sleep(20 * 60)\n",
    "        print('*' * 50)\n",
    "    print('Done :D\\nEnjoy it!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path where the set of tweets will be stored to play with them\n",
    "file_path = 'C:/Users/Javi/Desktop/cryptocurrency_predictor/data/twitter/raw_tweets.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 450/450 [04:30<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "794 new rows added to the csv.\n",
      "3 laps to go.\n",
      "Getting some sleep @ 00:25:55...\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 450/450 [04:38<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "671 new rows added to the csv.\n",
      "2 laps to go.\n",
      "Getting some sleep @ 00:50:34...\n",
      "**************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 450/450 [04:41<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "658 new rows added to the csv.\n",
      "1 laps to go.\n",
      "Getting some sleep @ 01:15:19...\n"
     ]
    }
   ],
   "source": [
    "long_term_retrieval(file_path, iterations=3, last_id=largest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Truncated tweets\n",
    "Texts over 140 characters are truncated. There could be a solution, adding `tweet_mode='extended'` parameter when calling my \"retrive_tweets\" function. <br>\n",
    "Let's see it in action!\n",
    "\n",
    "AND IT WORKS!!! We got the full text of the tweet! Take that Twitter!\n",
    "It doesn't work for retweets though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First look at the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'C:/Users/Javi/Desktop/cryptocurrency_predictor/data/twitter/raw_tweets.csv'\n",
    "columns = ['tweet_id',\n",
    "           'text',\n",
    "           'screen_name',\n",
    "           'followers',\n",
    "           'retweet_count',\n",
    "           'favorite_count', \n",
    "           'created_at',\n",
    "           'source']\n",
    "\n",
    "data = pd.read_csv(file_path, names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1553885 entries, 0 to 1553884\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count    Dtype \n",
      "---  ------          --------------    ----- \n",
      " 0   tweet_id        1553885 non-null  int64 \n",
      " 1   text            1553885 non-null  object\n",
      " 2   screen_name     1553885 non-null  object\n",
      " 3   followers       1553885 non-null  int64 \n",
      " 4   retweet_count   1553885 non-null  int64 \n",
      " 5   favorite_count  1553885 non-null  int64 \n",
      " 6   created_at      1553885 non-null  object\n",
      " 7   source          1529871 non-null  object\n",
      "dtypes: int64(4), object(4)\n",
      "memory usage: 94.8+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>followers</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>created_at</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1553880</th>\n",
       "      <td>1373427943234473993</td>\n",
       "      <td>We have exactly 23H to close this in a bullish...</td>\n",
       "      <td>crypto8260</td>\n",
       "      <td>261</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-21 00:15:13</td>\n",
       "      <td>Twitter for Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553881</th>\n",
       "      <td>1373427943318360067</td>\n",
       "      <td>@elliotrades $vxv vectorspace ai\\n\\nSo what's ...</td>\n",
       "      <td>Mrcryptopia</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-21 00:15:13</td>\n",
       "      <td>Twitter for Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553882</th>\n",
       "      <td>1373427944991956993</td>\n",
       "      <td>RT @ZerrBenz: BTCST Community AIRDROP Event\\n\\...</td>\n",
       "      <td>Lebr00n</td>\n",
       "      <td>401</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-21 00:15:13</td>\n",
       "      <td>Twitter for Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553883</th>\n",
       "      <td>1373427945109340164</td>\n",
       "      <td>#AffiliateMarketing #crypto #cryptocurrency #m...</td>\n",
       "      <td>bmurphypointman</td>\n",
       "      <td>69733</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-21 00:15:13</td>\n",
       "      <td>ContentStudio.io</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553884</th>\n",
       "      <td>1373427948536131584</td>\n",
       "      <td>Do you see what I see ??  for BITSTAMP:BTCUSD ...</td>\n",
       "      <td>bitcoinagile</td>\n",
       "      <td>56355</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-03-21 00:15:14</td>\n",
       "      <td>bitcoinagile</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    tweet_id  \\\n",
       "1553880  1373427943234473993   \n",
       "1553881  1373427943318360067   \n",
       "1553882  1373427944991956993   \n",
       "1553883  1373427945109340164   \n",
       "1553884  1373427948536131584   \n",
       "\n",
       "                                                      text      screen_name  \\\n",
       "1553880  We have exactly 23H to close this in a bullish...       crypto8260   \n",
       "1553881  @elliotrades $vxv vectorspace ai\\n\\nSo what's ...      Mrcryptopia   \n",
       "1553882  RT @ZerrBenz: BTCST Community AIRDROP Event\\n\\...          Lebr00n   \n",
       "1553883  #AffiliateMarketing #crypto #cryptocurrency #m...  bmurphypointman   \n",
       "1553884  Do you see what I see ??  for BITSTAMP:BTCUSD ...     bitcoinagile   \n",
       "\n",
       "         followers  retweet_count  favorite_count           created_at  \\\n",
       "1553880        261              0               0  2021-03-21 00:15:13   \n",
       "1553881        354              0               0  2021-03-21 00:15:13   \n",
       "1553882        401             22               0  2021-03-21 00:15:13   \n",
       "1553883      69733              0               0  2021-03-21 00:15:13   \n",
       "1553884      56355              0               0  2021-03-21 00:15:14   \n",
       "\n",
       "                      source  \n",
       "1553880  Twitter for Android  \n",
       "1553881  Twitter for Android  \n",
       "1553882  Twitter for Android  \n",
       "1553883     ContentStudio.io  \n",
       "1553884         bitcoinagile  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.info())\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest = data['tweet_id'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ended up with over 1,500,000 tweets extracted from the Twitter API throughout 4 weeks (28 days), from 21/02/2021 to 21/03/2021. Let's see how much meaningful info we can get from all of this.\n",
    "\n",
    "Head over to the next notebook!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
